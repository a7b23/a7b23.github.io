
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
	<meta name=viewport content='width=800'>
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
      /* Color scheme stolen from Sergey Karayev */
      a {
      color: #1772d0;
      text-decoration:none;
      }
      a:focus, a:hover {
      color: #f09228;
      text-decoration:none;
      }
      body,td,th {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 12px
      }
      strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 12px;
      }
      heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22 px;
      }
      papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 13px;
      font-weight: 700
      }
      name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
      }
	.fade {
	   transition: opacity .2s ease-in-out;
	   -moz-transition: opacity .2s ease-in-out;
	   -webkit-transition: opacity .2s ease-in-out;
	   }
	  


	img {
	    display: inline;
	    margin: 0 auto;
	    width: 100%;
	}
   .image-cropper {
      width: 250px;
      height: 250px;
      position: relative;
      overflow: hidden;
      border-radius: 50%;
  }
   .redText { 
    color: red; 
	} 	    
    </style>
    <link rel="icon" type="image" href="img/logo.jpg">
    <title>Abhishek Sinha</title>
    <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
    <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
    <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
      <tr>
        <td>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="67%" valign="middle">
                <p align="center">
                  <name>Abhishek Sinha</name>
                  </font>
                <p align>I am a second year graduate student in the department of Computer Science at <a href="https://www.stanford.edu/">Stanford University.</a> 
                  I am interested in the domain of computer vision and deep learning. I am specifically interested in topics such as generative models, anomaly detection, self-supervised learning and active learning.


                                  <br><br>
				  I am currently a Research Assistant under Professor Stefano Ermon and am pursuing research in generative models. Previously
                                  I was a Course Assistant for the couse <a href="http://web.stanford.edu/class/cs330/"> CS 330</a> - "Deep Multi Task and Meta Learning" taught by Professor Chelsea Finn.
                  <br><br>
                  Prior to coming here, I was working at Adobe India as Member of Technical Staff-2. I worked on a deep learning based visual search product for clothing based recommendation which accepts images, segments them and then recommends related desired products. This work won the "Best Paper Award" at a CVPR workshop, 2019. I was also involved in several other research based projects during my work.
                  Prior to my work, I did my undergraduation from <a href="http://www.iitkgp.ac.in/">Indian Institute of Tenchnology Kharagpur</a> with a major in Electronics and Electrical Communication Engineering and a minor in Computer Science.
                 
                <p align=center>
<a href="mailto:a7b23@stanford.edu">Email</a> &nbsp/&nbsp
<a href="https://www.linkedin.com/in/abhisheksinha94/">LinkedIn</a> &nbsp/&nbsp
<a href="files/resume.pdf">Resume</a> &nbsp/&nbsp
<a href="https://scholar.google.com/citations?hl=en&user=2llY8lwAAAAJ">Google Scholar</a>

                </p>
              </td>
              <td width="33%"><img class="image-cropper" src="img/photo.jpg"></td>
            </tr>
          </table>
            

           <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <heading style="font-size:22px">Selected Publications</heading>
              </td>
            </tr>
		
            <tr >
            
                    <td width="30%"><img id="img-opt" src="img/NDA.png" alt="project_img" width="160" style="border-style: none">
                    </td>
        
                        <td valign="top" width="70%">
                        <p><a target="_blank" rel="noopener noreferrer" href="https://openreview.net/pdf?id=Ovp8dvB8IBH">
            <papertitle>Negative Data Augmentation</papertitle></a><br>
                        
                        <p>Proposed a new GAN training objective to incorporate negative data augmentation.
                        <br><br>
                        Obtained significant gain in conditional/unconditional image generation and anomaly detection using the discriminator.
			<br><br>
			Incorporated negative augmentations for contrastive learning based approaches for images and videos and achieved gains in linear classification.
                        <br><br>
                        The work was accepted at <span class="redText"> ICLR, 2020 </span>.
                        </p>
                        </a> </p>
                        </td>
                    </tr>

            <tr >
            
                    <td width="30%"><img id="img-opt" src="img/introspection.png" alt="project_img" width="160" style="border-style: none">
                    </td>
        
                        <td valign="top" width="70%">
                        <p><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/pdf/1704.04959.pdf">
            <papertitle>Introspection: Accelerating Neural Network Training By Learning Weight Evolution</papertitle></a><br>
                        
                        <p>Developed an algorithm to speed up training of deep neural networks by predicting future weight values.
                        <br><br>
                        Achieved 20% and 40% improvement in training time for Cifar-10 and ImageNet datasets respectively.
                        <br><br>
                        The work was accepted at <span class="redText"> ICLR, 2017 </span>.
                        </p>
                        </a> </p>
                        </td>
                    </tr>
            <tr >
              <td width="30%"><img id="img-opt" src="img/few_shot.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/pdf/1907.12087.pdf">
        <papertitle>Charting the Right Manifold: Manifold Mixup for Few-shot Learning</papertitle></a><br>
                        
                      <p>Used self-supervision techniques - rotation and exemplar, followed by manifold mixup for few-shot classification tasks.
                      <br><br>
                      The proposed approach beats the current state-of-the-art accuracy on mini-ImageNet, CUB and CIFAR-FS datasets by 3-8%.
                      <br><br>
			      Work accepted at <span class="redText"> WACV, 2020 </span>.       
                      </p>
                      </a> </p>
                    </td>
                  </tr>
            <tr >
              <td width="30%"><img id="img-opt" src="img/lat.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/pdf/1905.05186.pdf">
        <papertitle>Harnessing the Vulnerability of Latent Layers in Adversarially Trained Models</papertitle></a><br>
                        
                      <p>Analyzed the adversarial trained models for vulnerability against adversarial perturbations at the latent layers.
                      <br><br>
                      The algorithm achieved the state-of-the art adversarial accuracy against strong adversarial attacks.      
                      <br><br>
			      Work accepted at <span class="redText"> IJCAI, 2019 </span>.
                      </p>
                       
                      </a> </p>
                    </td>
                  </tr>    

            <tr >
              <td width="30%"><img id="img-opt" src="img/language_grounding.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/pdf/1804.08454.pdf">
        <papertitle>Attention Based Natural Language Grounding By Navigating Virtual Environment</papertitle></a><br>
                        
                      <p>Made a 2D grid environment in which an agent performs tasks on the basis of natural language sentence. Developed a new fusion mechanism for the fusion of visual and textual features to solve the problem.
                      <br><br>
                      The proposed methodology outperformed the state-of-the-art in terms of both speed and performance for the 2D as well as a 3D environment.     
                      <br><br>
			      Work accepted at <span class="redText"> WACV, 2019 </span>.
                      </p>
                       
                      </a> </p>
                    </td>
                  </tr>    
            
            <tr >
              <td width="30%"><img id="img-opt" src="img/fashion.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a target="_blank" rel="noopener noreferrer" href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/FFSS-USAD/Chopra_Powering_Robust_Fashion_Retrieval_With_Information_Rich_Feature_Embeddings_CVPRW_2019_paper.pdf">
        <papertitle>Powering Robust Fashion Retrieval with Information Rich Feature Embeddings</papertitle></a><br>
                        
                      <p>Proposed a grid based training of siamese networks, allowing the network to observe mutiplte positive and negative image instances simultaneously.     
                      <br><br>
			      Best Paper Award at <span class="redText"> CVPR Workshop, 2019 </span>.
                      </p>
                       
                      </a> </p>
                    </td>
                  </tr>  
            
            <tr >
              <td width="30%"><img id="img-opt" src="img/adversarial.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/pdf/2005.01499.pdf">
        <papertitle>On The Benefits Of Models With Perceptually ALigned Gradients</papertitle></a><br>
                        
                      <p>Analyzed the models adversarially trained with small perturbation. Such models have interpretable gradients without incurring a significant drop in the performance over clean images.
                      <br><br>
                      Used these models for zero-shot transfer and weakly supervised object localization tasks, achieveing significant gains in performance.
                      <br><br>
            Work accepted at <span class="redText"> ICLR 2020 Workshop:  </span>Towards Trustworthy ML.
                      </p>
                       
                      </a> </p>
                    </td>
                  </tr>

            <tr >
              <td width="30%"><img id="img-opt" src="img/finegan.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/pdf/1912.05028.pdf">
        <papertitle>cFineGAN: Unsupervised multi-conditional fine-grained image generation</papertitle></a><br>
                        
                      <p>Proposed a multi-conditional image generation pipeline that generates an image which contains the shape of first input and texture of second input image.
                      
                      <br><br>
            Work accepted at <span class="redText"> NeurIPS Workshop </span>on Machine Learning for Creativity and Design 3.0, 2019.
                      </p>
                       
                      </a> </p>
                    </td>
                  </tr>

            <tr>
              <td width="30%"><img id="img-opt" src="img/custom_kernel.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a target="_blank" rel="noopener noreferrer" href="http://delivery.acm.org/10.1145/3330000/3321923/p159-ayush.pdf?ip=128.12.246.27&id=3321923&acc=ACTIVE%20SERVICE&key=AA86BE8B6928DDC7%2E0AF80552DEC4BA76%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1569044029_84099ab16a4d0a6b39df20f43c1e2490">
        <papertitle>Improving Classification Performance of Support VectorMachines via Guided Custom Kernel Search</papertitle></a><br>
                        
                      <p>Used a modification of the neural architecture search to discover a kernel function for SVM over MNIST dataset.   
                      <br><br>
			      Work accepted at <span class="redText"> GECCO, 2019 </span>.
                      </p>
                       
                      </a> </p>
                    </td>
                  </tr>

            
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tr>
                <td>
                  <heading style="font-size:22px">Selected Projects</heading>
                </td>
              </tr>
              <tr >
                <td width="30%"><img id="img-pgp" src="img/face_analyzer.jpg" alt="project_img" width="160" style="border-style: none">
                    </td>
        
                      <td valign="top" width="70%">
                        <p><a href="">Face analyzer tool</papertitle></a><br>
                        

                        <p>Built a face analyzer tool utilizing  deep learning techniques to provide users with an unbiased analysis of their facial appearance.
                        <br><br>
                        The project was the <span class="redText">winner of the Microsoft AI Hackathon</span> competition held at IIT Kharagpur.
                      <!--   <p></p>
                        <a href="files/report_pgp.pdf">report</a> | <a href="files/slides_pgp.pdf">slides</a>
                        </a> </p> -->
                      </td>
                    </tr>

              <tr >
                <td width="30%"><img id="img-pgp" src="img/deep_rl_snake.jpg" alt="project_img" width="160" style="border-style: none">
                    </td>
        
                      <td valign="top" width="70%">
                        <p><a href="">Autonomous snake game using DQN</papertitle></a><br>
                        

                        <p>Implemented Deep Q learning for the snake game. Built the game in pygame which could be then controlled by a deep learning agent.
                        </p>
                      <!--   <p></p>
                        <a href="files/report_pgp.pdf">report</a> | <a href="files/slides_pgp.pdf">slides</a>
                        </a> </p> -->
                      </td>
                    </tr>

            <!-- <tr >
        
                <td width="30%"><img id="img-opt" src="img/zsl.png" alt="project_img" width="160" style="border-style: none">
                </td>
    
                  <td valign="top" width="70%">
                    <p><a href="files/cs772.pdf">
      <papertitle>A survey of Zero Shot Learning</papertitle></a><br>
                      <em>Supervisor: <a href="https://www.cse.iitk.ac.in/users/piyush/">Dr. Piyush Rai</a>, Indian Institute of Technology Kanpur</em><br>
                    <p>Studied different methods of performing Zero Shot Learning(ZSL) - prediction of a label that
                      has been not seen during the training procedure. 
                    <br><br>
                    Implemented two contemporary papers from this area which required learning a common semantic
                    space for embedding images and labels, to perform ZSL task. Focused on dictionary learning as a way to resolve the PDS issue and found that CNN based features drastically improve the classification accuracy.          
                    <p></p>
                    <a href="files/cs772.pdf">report</a> | <a href="files/cs772_poster.pdf">poster</a>
                    </a> </p>
                  </td>
                </tr>

                <tr >
                    <td width="30%"><img id="img-opt" src="img/isomap.png" alt="project_img" width="160" style="border-style: none">
                        </td>
                          <td valign="top" width="70%">
                            <p><a href="files/ee609.pdf">
              <papertitle>Visualization of high dimensional data </papertitle></a><br>
                              <em>Supervisor: <a href = "http://home.iitk.ac.in/~ketan/">Dr. Ketan Rajawat</a>, Indian Institute of Technology Kanpur</em><br>
                            <p>Explored applications of convex optimization for dimensionality reduction, especially
                              over non linear manifolds.
                            <br><br>
                            Compared performance based on visualizations, computational complexities, and error rates
                            obtained in classification tasks. Selected as the <b>best project</b> in the course comprising of over 80 students.
                            <p></p>
                            <a href="files/ee609.pdf">report</a>
                            </a> </p>
                          </td>
                        </tr>
                        <tr >

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tr>
                <td>
                  <heading style="font-size:22px">Internships</heading>
                </td>
              </tr>
              <tr >
                <td width="30%"><img id="img-pgp" src="img/samsung.jpeg" alt="project_img" width="160" style="border-style: none">
                    </td>
        
                      <td valign="top" width="70%">
                        <p><a href="http://www.samsung.com/in/aboutsamsung/samsungelectronics/india/rnd/">
          <papertitle>Samsung Research and Development Institute, Bengaluru (SRIB)</papertitle></a><br>
                          <em>Supervisor: Vishwanath Gopalakrishnan, Principal Engineer, SRIB</em> <br>

                        <p>Developed a photo search mobile application based on image classification by using memory efficient CNN architectures.
                        <br><br>
                        Implemented a depth prediction module for 2D images by formulating it as a dense-label regression problem.
                      <!--   <p></p>
                        <a href="files/report_pgp.pdf">report</a> | <a href="files/slides_pgp.pdf">slides</a>
                        </a> </p> -->
                      </td>
                    </tr>

                    


            <tr> 
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <br>
                <p align="right"><font size="2">
                  <a href="http://www.cs.berkeley.edu/~barron/">inspired from this website</a>
                  <!-- <a href="http://www.cs.berkeley.edu/~barron/"> this website</a> -->
                  </font>
                </p>
              </td>
            </tr>
          </table>
        </td>
      </tr>
    </table>
 <!-- Default Statcounter code for Personal Website
https://shrep.github.io/ -->
<script type="text/javascript">
var sc_project=11673319; 
var sc_invisible=1; 
var sc_security="327094c7"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics
Made Easy - StatCounter" href="http://statcounter.com/"
target="_blank"><img class="statcounter"
src="//c.statcounter.com/11673319/0/327094c7/1/" alt="Web
Analytics Made Easy - StatCounter"></a></div></noscript>
<!-- End of Statcounter Code -->
  </body>
</html>
